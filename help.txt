DocuLink – Multilingual RAG Application for Corporate Knowledge 
1. Introduction 
1.1 Background 
Large enterprises generate massive volumes of unstructured documents: policies, contracts, incident reports, 
technical drawings, maintenance logs, scanned PDFs, and emails. These often sit scattered across tools like 
email, SharePoint, Maximo, network drives, and cloud folders. 
Employees waste time searching, re-reading, and forwarding documents instead of getting direct answers to 
business questions (e.g., “What is the SOP for signal failure?” or “What’s the latest safety policy for platform 
operations?”). 
1.2 Problem Statement 
Traditional document management systems are: 
• Siloed – each department has its own tools and folders. 
• Search-poor – keyword search struggles with PDFs, images, bilingual content, and domain-specific 
jargon. 
• Not conversational – users must know file names or keywords instead of asking questions in 
natural language. 
• Not multilingual – especially for organizations where English and a local language (e.g., Malayalam) 
coexist. 
There is a clear need for a central, intelligent, multilingual knowledge layer across all corporate 
documents that can: 
• Understand English and Malayalam, 
• Work over PDFs, scans, images, technical documents, 
• Provide traceable, source-linked answers, and 
• Be accessible via mobile chat + voice for on-ground staff. 
2. Project Objectives 
DocuLink is designed to: 
1. Centralize corporate documents into a single, searchable knowledge repository. 
2. Enable multilingual RAG (Retrieval-Augmented Generation) across English and Malayalam 
documents. 
3. Provide conversational access via Android app (text + voice). 
4. Support role-based, department-specific access for different corporate functions.  
5. Automate ingestion and embedding of documents from multiple sources (email, SharePoint, 
Maximo, uploaded files). 
6. Deliver trustworthy answers with citations pointing back to original documents. 
7. Scale to enterprise workloads using OpenSearch, Redis, and a microservice-style backend. 
3. System Description (High-Level) 
DocuLink is a mobile-first corporate knowledge system with: 
• An Android app (Kotlin) that provides: 
o Secure login (Firebase Auth) 
o Chat-style interface 
o Voice input (speech-to-text) 
o A dashboard of embedded documents 
• A Python FastAPI backend that: 
o Stores and searches document embeddings in OpenSearch (vector + hybrid search). 
o Uses Vyākhyarth (vyakyarth) multilingual embedding model for English/Malayalam 
vectorization. 
o Calls Gemini for answer generation, guided by retrieved context. 
o Orchestrates document ingestion and embeddings via Redis-backed queues and workers. 
• A document ingestion & processing pipeline that:  
o Accepts uploads (from Android app, email, cloud links). 
o Performs OCR for scanned PDFs/images. 
o Detects language (English/Malayalam). 
o Summarizes and categorizes documents. 
o Stores embeddings + metadata in OpenSearch and references in Firestore. 
4. Proposed Solution 
4.1 Central Knowledge Repository 
A single OpenSearch index (plus supporting indices) acts as the corporate knowledge base for all ingested 
documents. DocuLink stores: 
• Raw text chunks (extracted from PDFs, images, etc.) 
• Vector embeddings (using Vyākhyarth) 
• Metadata (department, type, date, source system, language, access role) 
4.2 Secure Ingestion Gateway 
Documents can arrive via:  
• Android upload (Firebase Storage → embedding pipeline) 
• Enterprise systems (e.g., Maximo, SharePoint) 
• Emails and cloud links (future connectors) 
Each file is queued in Redis for: 
1. OCR & text extraction 
2. Language detection (en / ml) 
3. Chunking and embedding 
4. Indexing into OpenSearch 
4.3 Conversational Multilingual RAG 
The Android app sends user queries to /api/query. Backend pipeline: 
1. Generate multilingual embedding of the query. 
2. Hybrid search in OpenSearch (BM25 + vector similarity). 
3. Select top-k context chunks with metadata. 
4. Construct a prompt for Gemini with instructions: 
o Answer in Malayalam if question is Malayalam, else English. 
o Use context, and mention if context is insufficient. 
5. Return answer + citations to the app, which displays it as chat bubbles. 
5. Technical Approach 
5.1 RAG Architecture 
• Retriever: 
o Vyākhyarth embedding model to embed both English & Malayalam queries and chunks. 
o Hybrid search in OpenSearch (vector + keyword) for robust retrieval. 
• Generator (LLM): 
o Gemini 2.0 Flash via Google Generative AI API. 
o Custom prompt instructing role-aware, multilingual behavior, grounded in context. 
• Indexing: 
o Documents are split into chunks (e.g., 512–1024 tokens). 
o Each chunk stored with: 
▪ document_id, chunk_index, text, similarity_score (later), department, language, 
source. 
5.2 Android Client 
• Authentication: 
o Firebase Authentication (email/password). 
• UI: 
o ChatActivity with drawer navigation (Dashboard, Embedded Documents). 
o Chat bubbles for user and system messages. 
o Voice input using Android RecognizerIntent (supports en-IN, ml-IN). 
o “Embedded Documents” screen with a RecyclerView of DocumentItem. 
• Networking: 
o Http.sendQuery() uses HttpURLConnection to POST JSON to 
http://127.0.0.1:8080/api/query (via adb reverse). 
o Response parsed into QueryResponse, and response field displayed in chat. 
• Document Uploads: 
o EmbeddedDocumentsActivity uses Android Storage Access Framework to pick files. 
o Uploads to Firebase Storage, writes metadata to Firestore with status = 
"embedding_in_progress" and shows toast: 
▪ “Embedding started… Estimated time ≈ 10 minutes.” 
o Backend (or future pipeline) flips status to ready after embeddings are computed. 
5.3 Backend & Pipelines 
• FastAPI service: 
o Endpoints: /api/query, /api/health, /api/departments, /api/stats, /api/speech-to-text. 
o Asynchronous handlers using async/await and ThreadPoolExecutor for blocking operations. 
• OpenSearch: 
o Dedicated index embeddings_index for document chunks. 
o Hybrid search function implemented in OpenSearchQueryProcessor. 
• Redis Queue (planned/used): 
o For asynchronous embedding + indexing of new documents. 
• Speech-to-text endpoint: 
o /api/speech-to-text accepts audio files and leverages Gemini’s multimodal capabilities for 
transcription (optional alternative to device STT). 
6. Tech Stack 
Frontend (Android) 
• Language: Kotlin 
• Framework: Native Android (View-based UI) 
• Libraries/Services: 
o Firebase Auth (user management) 
o Firebase Firestore (document metadata) 
o Firebase Storage (file uploads) 
Backend 
• API: Python, FastAPI 
• LLM: Google Gemini 2.0 Flash 
• Embeddings: Vyākhyarth multilingual embedding model 
• Search Engine: OpenSearch (vector + BM25 hybrid) 
• Queue / Orchestration: Redis + background workers (e.g., Celery/RQ or custom workers) 
• Storage: 
o OpenSearch indices 
o (Optional) PostgreSQL / other DB for structured metadata & job tracking 
Infrastructure & Tools 
• adb reverse for Android → local backend connectivity during development 
• Logging via Python logging module 
• JSON serialization via pydantic and Gson (Android) 
7. System Workflow 
7.1 Document Ingestion Flow 
1. User uploads a file from Android. 
2. File stored in Firebase Storage; metadata written to Firestore with status = 
"embedding_in_progress". 
3. Document path pushed to Redis queue for processing. 
4. Worker: 
o Downloads file 
o Runs OCR/Text extraction & language detection 
o Chunks text and computes Vyākhyarth embeddings 
o Indexes chunks into OpenSearch with metadata 
o Updates Firestore status = "ready". 
5. Android app receives updated status via Firestore snapshot listener and displays “Embedded” in list. 
7.2 Query → Answer Flow 
1. User enters text or uses voice in Android. 
2. App sends QueryRequest to FastAPI /api/query. 
3. Backend: 
o Generates embedding for query. 
o Runs hybrid search in OpenSearch. 
o Builds context prompt and calls Gemini. 
o Returns QueryResponse with response and context_documents. 
4. App shows system reply as chat bubble, while optionally allowing future UI to display “Sources” 
from context_documents. 
8. Feasibility and Viability 
8.1 Technical Feasibility 
• All components (Android, FastAPI, OpenSearch, Redis, Gemini) are mature and well-documented. 
• RAG architecture is a proven pattern for enterprise knowledge management. 
• Vyākhyarth embeddings + Gemini handle English/Malayalam mix, which matches real corporate 
usage. 
8.2 Operational Feasibility 
• Mobile-first access is ideal for field staff, supervisors, and managers. 
• Existing corporate systems (SharePoint, Maximo, email) can be connected incrementally via ingestion 
connectors. 
• Role-based access and department-level scoping align with existing organizational structures.  
8.3 Economic Viability 
• OpenSearch and Redis are open-source, reducing infrastructure licensing costs. 
• Gemini usage can be controlled via quotas and caching, with potential to swap to alternative models 
if required. 
• Time saved in retrieval, compliance checks, and incident handling can justify the deployment cost, 
especially for large document-heavy organizations. 
9. Challenges and Mitigation Strategies 
1. LLM / API Quotas & Costs 
o Challenge: External LLM (Gemini) has rate and cost limits. 
o Strategy: 
▪ Aggressive retrieval to minimize tokens per call. 
▪ Result caching for repeated queries. 
▪ Fallback explanations when quota exceeded (handled gracefully in Android UI). 
2. Data Privacy & Security 
o Challenge: Corporate documents may be sensitive (financials, incident reports, HR). 
o Strategy: 
▪ Secure storage and network (HTTPS, access control). 
▪ Role-based metadata and filtered retrieval. 
▪ Consider on-prem or VPC-hosted OpenSearch and backend for regulated sectors. 
3. Multilingual Accuracy (English/Malayalam) 
o Challenge: Code-mixed queries and bilingual documents. 
o Strategy: 
▪ Use a multilingual embedding model (Vyākhyarth). 
▪ Prompt engineering to enforce language-specific answer behavior. 
▪ Continual evaluation with real corporate queries. 
4. Document Quality (Scans, Images, Old PDFs) 
o Challenge: Poor scans and legacy documents reduce OCR quality. 
o Strategy: 
▪ Pre-processing: image enhancement, DPI checks. 
▪ Human-in-the-loop review for low-confidence OCR. 
▪ Flagging of low-quality sources in metadata and UI. 
5. User Adoption 
o Challenge: Employees may still search manually or rely on email chains. 
o Strategy: 
▪ Simple chat-style UX and voice input. 
▪ Demonstrate fast answers vs. manual search. 
▪ Start with high-value use cases (safety, compliance, incident handling). 
10. Impact and Benefits 
For corporate clients, DocuLink delivers:  
• Single Source of Truth for all documents, searchable in natural language. 
• Reduced Time-to-Answer for policy, SOP, and compliance questions. 
• Improved Safety & Compliance via fast retrieval of the latest rules and incident guidelines. 
• Empowered Frontline Staff with mobile & voice-accessible knowledge. 
• Better Governance with role-based access and document traceability (citations). 
• Scalable Foundation for future analytics like risk scoring, trend detection, and proactive alerts. 
11. Screenshots  
• Screenshot 1: Login screen (Firebase Auth) 
•  
• Screenshot 2: Metro Dashboard (Kochi Metro / corporate dashboard view) 
•  
• Screenshot 3: Chat screen showing bilingual query and answer (English & Malayalam) 
•  
•  
• Screenshot 4: Embedded Documents list with status (“Embedding in progress”, “Embedded”) 
•  
• Screenshot 5: Sidebar 
•  
12. GitHub Repository 
GitHub: https://github.com/Blessan-Alex/DocuLink 
13. Presentation Link 
Presentation: https://docs.google.com/presentation/ 
13. Research and References 
1. OpenSearch Documentation – Vector search, hybrid search, and index design for high-scale 
retrieval. 
2. Redis Documentation – Queues and background job processing for asynchronous ingestion. 
3. PostgreSQL / Relational DB Docs – For structured metadata, logging, and audit trails. 
4. Google Gemini API Docs – Generative model usage, safety, quotas, and best practices. 
5. Vyākhyarth Embedding Model Docs – Multilingual (English/Malayalam) sentence embeddings. 
6. OCR & Multilingual NLP – Tesseract OCR and related AI APIs for scanned document text 
extraction. 
7. Retrieval-Augmented Generation for Large Language Models: A Survey – Comprehensive overview of RAG 
design patterns. 
8. Case studies on intelligent document management in enterprises and AI-based compliance support. 